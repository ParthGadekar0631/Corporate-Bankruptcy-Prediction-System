{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyCqH_qS-Jrt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -----------------------------\n",
        "# STEP-1 Load test dataset\n",
        "# -----------------------------"
      ],
      "metadata": {
        "id": "TMxCvhHE-P6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"test_data.csv\")\n",
        "print(\"\\nTEST SHAPE:\", test_df.shape)"
      ],
      "metadata": {
        "id": "1tfnG23H-OKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------------\n",
        "# STEP-2 Load cluster-ID model\n",
        "# --------------------------------------"
      ],
      "metadata": {
        "id": "GIK7Jtlp-S_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_bundle = joblib.load(\"models/cluster_id_model.joblib\")\n",
        "cluster_feats = cluster_bundle[\"feature_cols\"]\n",
        "cluster_model = cluster_bundle[\"model\"]\n",
        "\n",
        "X_cluster = test_df[cluster_feats]\n",
        "test_df[\"cluster_id_pred\"] = cluster_model.predict(X_cluster)\n",
        "print(\"\\nCluster distribution:\\n\", test_df[\"cluster_id_pred\"].value_counts())"
      ],
      "metadata": {
        "id": "rhFEKYdq-W9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -------------------------------------\n",
        "# STEP-3  Load subgroup stacking models\n",
        "# -------------------------------------"
      ],
      "metadata": {
        "id": "vaqYUEIF-iDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subgroup_model_paths = {\n",
        "    0: \"models/subgroup0_stacking_bundle.joblib\",\n",
        "    #1: \"models/subgroup1_stacking_bundle.joblib\",\n",
        "    2: \"models/subgroup2_cluster2_model.joblib\",\n",
        "    #3: \"models/subgroup3_stacking_bundle.joblib\",\n",
        "}\n",
        "\n",
        "subgroups = {}\n",
        "\n",
        "for cid, path in subgroup_model_paths.items():\n",
        "    if os.path.exists(path):\n",
        "        bundle = joblib.load(path)\n",
        "        subgroups[cid] = {\n",
        "            \"model\": bundle[\"model\"],\n",
        "            \"features\": bundle[\"selected_features\"]\n",
        "        }\n",
        "        print(f\"âœ” Loaded Subgroup Model for Cluster {cid}\")\n",
        "    else:\n",
        "        print(f\"âš  No model for cluster {cid} â€” using constant 0 predictor\")"
      ],
      "metadata": {
        "id": "ou6PWXDZ-eK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------------\n",
        "# STEP-4 Predict bankruptcy per subgroup\n",
        "# --------------------------------------"
      ],
      "metadata": {
        "id": "cbS4hx0L-oQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.zeros(len(test_df), dtype=int)\n",
        "probs_all = np.zeros(len(test_df))  # needed for 20% ranking rule\n",
        "\n",
        "for cid, idx in test_df.groupby(\"cluster_id_pred\").groups.items():\n",
        "    rows = test_df.loc[idx]\n",
        "\n",
        "    if cid in subgroups:\n",
        "        model = subgroups[cid][\"model\"]\n",
        "        feats = subgroups[cid][\"features\"]\n",
        "        X_sub = rows[feats]\n",
        "\n",
        "        # probability for reduction stage\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            p = model.predict_proba(X_sub)[:,1]\n",
        "        else:\n",
        "            p = model.predict(X_sub)  # fallback classifier\n",
        "\n",
        "        probs_all[idx] = p\n",
        "        y_pred[idx] = (p >= 0.5).astype(int)  # raw before reduction\n",
        "\n",
        "        print(f\"Cluster {cid}: Pred bankrupt = {y_pred[idx].sum()}\")\n",
        "    else:\n",
        "        # cluster with no model predicts 0\n",
        "        y_pred[idx] = 0\n",
        "        probs_all[idx] = 0\n",
        "        print(f\"Cluster {cid}: No model â†’ forced bankrupt=0\")\n",
        "\n",
        "# ================================================================\n",
        "#  ðŸ”¥ 20% Bankruptcy Output Rule (Auto-Enforced)\n",
        "# ================================================================\n",
        "max_allowed = int(0.20 * len(test_df))   # 20% limit\n",
        "\n",
        "if y_pred.sum() > max_allowed:\n",
        "    print(f\"\\nâš  {y_pred.sum()} bankrupt predicted > limit {max_allowed}\")\n",
        "    print(\"Applying confidence reduction â†’ keeping only top 20% risky firms.\")\n",
        "\n",
        "    top_idx = np.argsort(probs_all)[-max_allowed:]   # pick most-probable bankrupt\n",
        "    y_final = np.zeros(len(test_df), dtype=int)\n",
        "    y_final[top_idx] = 1\n",
        "else:\n",
        "    print(f\"\\nðŸŸ¢ Bankruptcy count {y_pred.sum()}/{max_allowed} within allowed limit.\")\n",
        "    y_final = y_pred.copy()\n",
        "\n",
        "test_df[\"Bankrupt?\"] = y_final\n",
        "\n",
        "print(\"\\nFINAL BANKRUPTCY COUNT:\", test_df[\"Bankrupt?\"].sum(),\n",
        "      f\" (Capped at {max_allowed})\")\n"
      ],
      "metadata": {
        "id": "ko4ugWiA-mXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------------\n",
        "# STEP-5 Create submission file\n",
        "# --------------------------------------"
      ],
      "metadata": {
        "id": "3Il_ROV3-tiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = test_df[[\"Index\",\"Bankrupt?\"]]\n",
        "submission.to_csv(\"Group4_Generalization.csv\", index=False)\n",
        "\n",
        "print(\"\\n=================================================\")\n",
        "print(\" ðŸ“„ FINAL OUTPUT SAVED â†’ Group4_Generalization.csv\")\n",
        "print(\"=================================================\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "id": "ostPB5WR-yzM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}