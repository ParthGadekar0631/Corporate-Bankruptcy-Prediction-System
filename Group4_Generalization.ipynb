{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "yyCqH_qS-Jrt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Custom model class sometimes used in missing-bankrupt clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConstantModel:\n",
        "    def predict(self, X): return np.zeros(len(X))\n",
        "    def predict_proba(self, X):\n",
        "        return np.column_stack([np.ones(len(X)), np.zeros(len(X))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMxCvhHE-P6r"
      },
      "source": [
        "### =================\n",
        "### Load test dataset\n",
        "### ================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "1tfnG23H-OKn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading test dataset...\n",
            "Test rows: 1012\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nLoading test dataset...\")\n",
        "test_df = pd.read_csv(\"test_data.csv\")\n",
        "print(\"Test rows:\", len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIK7Jtlp-S_8"
      },
      "source": [
        "### =============================\n",
        "### LOAD CLUSTER ASSIGNMENT MODEL\n",
        "### ============================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "rhFEKYdq-W9A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ”¹ Running Stage-1 Feature Preprocessing & Cluster Assignment...\n",
            "\n",
            "Cluster Distribution in Test Data:\n",
            "Assigned_Cluster\n",
            "2    371\n",
            "3    354\n",
            "0    248\n",
            "1     39\n",
            "Name: count, dtype: int64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "stage1 = joblib.load(\"models/cluster_id_model.joblib\")   # dict stored\n",
        "cluster_model = stage1[\"model\"]                           # RF classifier\n",
        "cluster_features = stage1[\"feature_cols\"]                 # original inputs\n",
        "\n",
        "print(\"\\nðŸ”¹ Running Stage-1 Feature Preprocessing & Cluster Assignment...\")\n",
        "X_test_stage1 = test_df.drop(columns=[\"Index\"], errors=\"ignore\")[cluster_features]\n",
        "scaled_test = cluster_model.named_steps[\"scaler\"].transform(X_test_stage1)\n",
        "test_df[\"Assigned_Cluster\"] = cluster_model.named_steps[\"rf\"].predict(scaled_test)\n",
        "\n",
        "print(\"\\nCluster Distribution in Test Data:\")\n",
        "print(test_df[\"Assigned_Cluster\"].value_counts(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaqYUEIF-iDA"
      },
      "source": [
        "### =============================================\n",
        "### Load Available Subgroup Models Automatically\n",
        "### ============================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "ou6PWXDZ-eK5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading subgroup models available\n",
            "Loaded Model for Cluster 0\n",
            "Loaded Model for Cluster 2\n",
            "Loaded Model for Cluster 5\n",
            "\n",
            "Active Models â†’ [0, 2, 5]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nLoading subgroup models available\")\n",
        "subgroup_models = {}\n",
        "\n",
        "for file in os.listdir(\"models\"):\n",
        "    if file.startswith(\"subgroup\") and file.endswith(\"_model.joblib\"):\n",
        "        cid = int(file.split(\"_cluster\")[1].split(\"_\")[0])\n",
        "        subgroup_models[cid] = joblib.load(f\"models/{file}\")\n",
        "        print(f\"Loaded Model for Cluster {cid}\")\n",
        "\n",
        "active = list(subgroup_models.keys())\n",
        "print(\"\\nActive Models â†’\", active)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbS4hx0L-oQK"
      },
      "source": [
        "### ============================================\n",
        "### Predict Bankruptcy for Each Assigned Cluster\n",
        "### ============================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ko4ugWiA-mXc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================== CLUSTER-WISE PREDICTION ====================\n",
            "\n",
            "Processing Cluster 0 â†’ 248 rows\n",
            "Cluster 0: Predicted Bankrupt â†’ 44.0\n",
            "\n",
            "Processing Cluster 1 â†’ 39 rows\n",
            "No model for cluster 1 â†’ marking all = 0\n",
            "\n",
            "Processing Cluster 2 â†’ 371 rows\n",
            "Cluster 2: Predicted Bankrupt â†’ 2.0  (Threshold=0.01)\n",
            "\n",
            "Processing Cluster 3 â†’ 354 rows\n",
            "No model for cluster 3 â†’ marking all = 0\n"
          ]
        }
      ],
      "source": [
        "pred = np.zeros(len(test_df))\n",
        "prob = np.zeros(len(test_df))\n",
        "\n",
        "print(\"\\n==================== CLUSTER-WISE PREDICTION ====================\")\n",
        "\n",
        "for cid, idx in test_df.groupby(\"Assigned_Cluster\").groups.items():\n",
        "    print(f\"\\nProcessing Cluster {cid} â†’ {len(idx)} rows\")\n",
        "\n",
        "    # ðŸ”¸ If no Stage-2 model exists â†’ forced safe assignment (0)\n",
        "    if cid not in subgroup_models:\n",
        "        print(f\"No model for cluster {cid} â†’ marking all = 0\")\n",
        "        pred[idx] = 0\n",
        "        prob[idx] = 0\n",
        "        continue\n",
        "\n",
        "    bundle = subgroup_models[cid]\n",
        "\n",
        "    # ðŸ”¥ Format-1 â†’ (pipeline + threshold + feature list)  â†’ **Subgroup 2**\n",
        "    if isinstance(bundle, dict) and \"pipeline\" in bundle:\n",
        "        model = bundle[\"pipeline\"]\n",
        "        thr = bundle.get(\"threshold\", 0.5)\n",
        "        feats = bundle[\"feature_names\"]\n",
        "\n",
        "        X_sub = test_df.iloc[idx][feats]\n",
        "        prob[idx] = model.predict_proba(X_sub)[:,1]\n",
        "        pred[idx] = (prob[idx] >= thr).astype(int)\n",
        "\n",
        "        print(f\"Cluster {cid}: Predicted Bankrupt â†’ {pred[idx].sum()}  (Threshold={thr})\")\n",
        "\n",
        "    # ðŸ”¥ Format-2 â†’ {\"model\":model, \"selected_features\":...} â†’ Subgroup 0 & 5\n",
        "    elif isinstance(bundle, dict) and \"model\" in bundle:\n",
        "        model = bundle[\"model\"]\n",
        "        feats = bundle.get(\"selected_features\", test_df.columns)\n",
        "\n",
        "        X_sub = test_df.iloc[idx][feats]\n",
        "        prob[idx] = model.predict_proba(X_sub)[:,1]\n",
        "        pred[idx] = (prob[idx] >= 0.5).astype(int)\n",
        "\n",
        "        print(f\"Cluster {cid}: Predicted Bankrupt â†’ {pred[idx].sum()}\")\n",
        "\n",
        "    # ðŸ”¥ Format-3 â†’ Raw model\n",
        "    else:\n",
        "        model = bundle\n",
        "        X_sub = test_df.iloc[idx]\n",
        "\n",
        "        prob[idx] = model.predict_proba(X_sub)[:,1]\n",
        "        pred[idx] = (prob[idx] >= 0.5).astype(int)\n",
        "\n",
        "        print(f\"Cluster {cid}: Predicted Bankrupt â†’ {pred[idx].sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Il_ROV3-tiH"
      },
      "source": [
        "### =====================================\n",
        "### 20% RULE â€” Keep Only Most Risky Firms\n",
        "### ====================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ostPB5WR-yzM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total Predicted = 46.0  |  Allowed â‰¤ 202\n",
            "Below risk limit â€” Keeping model predictions as-is\n"
          ]
        }
      ],
      "source": [
        "max_allowed = int(0.20 * len(test_df))\n",
        "total_pred = pred.sum()\n",
        "\n",
        "print(f\"\\nTotal Predicted = {total_pred}  |  Allowed â‰¤ {max_allowed}\")\n",
        "\n",
        "if total_pred > max_allowed:\n",
        "    print(\"Exceeds limit â€” Keeping HIGH-RISK only (top probability sorting)\")\n",
        "    top = np.argsort(prob)[-max_allowed:]\n",
        "    final = np.zeros(len(test_df),dtype=int)\n",
        "    final[top] = 1\n",
        "else:\n",
        "    print(\"Below risk limit â€” Keeping model predictions as-is\")\n",
        "    final = pred.copy()\n",
        "\n",
        "test_df[\"Bankrupt?\"] = final.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ============================\n",
        "### Export Final Submission File\n",
        "### ============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================================================\n",
            "   FINAL OUTPUT SAVED â†’ Group4_Generalization.csv\n",
            "==============================================================\n",
            "\n",
            "   Index  Bankrupt?\n",
            "0      0          0\n",
            "1      1          0\n",
            "2      2          0\n",
            "3      3          0\n",
            "4      4          0\n"
          ]
        }
      ],
      "source": [
        "output = test_df[[\"Index\",\"Bankrupt?\"]]\n",
        "output.to_csv(\"Group4_Generalization.csv\", index=False)\n",
        "\n",
        "print(\"\\n==============================================================\")\n",
        "print(\"   FINAL OUTPUT SAVED â†’ Group4_Generalization.csv\")\n",
        "print(\"==============================================================\\n\")\n",
        "print(output.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
